{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46984f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b156ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier(\"./res/haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv.CascadeClassifier(\"./res/haarcascade_eye.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c7241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_for_crop(img_address):\n",
    "    img = cv.imread(img_address)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (w>200 and h>200):\n",
    "            return x,y,x+w,y+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7718eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   usaldusväärsus  180 non-null    float64\n",
      " 1   ilu             180 non-null    float64\n",
      " 2   intelligents    180 non-null    float64\n",
      " 3   pilt            210 non-null    object \n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 6.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defineerime CSV faili tee ja piltide peamise kausta tee\n",
    "csv_file_path = './res/ratings.csv'\n",
    "images_folder_path = './res/people'\n",
    "\n",
    "# Laadime CSV faili\n",
    "df = pd.read_csv(csv_file_path, header=None)\n",
    "\n",
    "# Loome tühja DataFrame, kuhu salvestame ümberstruktureeritud andmed\n",
    "columns = ['usaldusväärsus', 'ilu', 'intelligents', \"pilt\"]\n",
    "andmestik_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Itereerime läbi CSV andmete ja lisame need ümberstruktureeritult uude DataFrame'i\n",
    "for index, row in df.iterrows():\n",
    "    # Määrame kausta nime vastavalt rea indeksile\n",
    "    folder_name = f'id{index + 1}'\n",
    "    folder_path = os.path.join(images_folder_path, folder_name)\n",
    "    \n",
    "    # Lisame andmed vastavalt kaustas olevatele piltidele\n",
    "    for i in range(0, len(row)-3, 3):\n",
    "        image_name = f'Allalaaditud fail ({i//3 + 1}).jpeg'\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        \n",
    "        # load the image and convert into\n",
    "        # numpy array\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        #crop image so it will only contain the face of the person\n",
    "        img = img.crop(coords_for_crop(image_path))\n",
    "        \n",
    "        #resize image to 600x600 \n",
    "        img = img.resize((600,600))\n",
    "        \n",
    "        ##\n",
    "        #img.show()\n",
    "        ##\n",
    "        \n",
    "        # asarray() class is used to convert\n",
    "        # PIL images into NumPy arrays\n",
    "        image_array = asarray(img)\n",
    "        \n",
    "        \n",
    "        image_data = pd.DataFrame({\n",
    "            'usaldusväärsus': [row[i]],\n",
    "            'ilu': [row[i+1]],\n",
    "            'intelligents': [row[i+2]],\n",
    "            'pilt': [image_array]  \n",
    "        })\n",
    "        andmestik_df = pd.concat([andmestik_df,image_data], ignore_index=True)\n",
    "\n",
    "\n",
    "# Kui soovite tulemused salvestada uude CSV faili\n",
    "andmestik_df.to_csv('./res/reshaped_file.csv', index=True)\n",
    "# Vaatame ümberstruktureeritud andmeid\n",
    "print(andmestik_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93812f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kost\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 24s/step - loss: 3905.6277 - mae: 36.3586 - val_loss: 98.4915 - val_mae: 9.6897\n",
      "Epoch 2/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 20s/step - loss: 73.6707 - mae: 7.9896 - val_loss: 16.2720 - val_mae: 3.5023\n",
      "Epoch 3/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 20s/step - loss: 15.4514 - mae: 3.2180 - val_loss: 9.7517 - val_mae: 2.6090\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 560ms/step - loss: 7.9378 - mae: 2.3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation - Loss: 7.789496421813965, MAE: 2.3294103145599365\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = andmestik_df\n",
    "\n",
    "# Drop rows with missing ratings\n",
    "df = df.dropna(subset=['usaldusväärsus', 'ilu', 'intelligents'])\n",
    "\n",
    "# Extract the images and labels\n",
    "images = np.stack(df['pilt'].values)\n",
    "ratings = df[['usaldusväärsus', 'ilu', 'intelligents']].values\n",
    "\n",
    "# Normalize image data\n",
    "images = images / 255.0\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(600, 600, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3)  # Output layer for the 3 ratings\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=25, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Model evaluation - Loss: {loss}, MAE: {mae}')\n",
    "\n",
    "# Save the model\n",
    "model.save('face_ratings_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f14c7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = load_model('face_ratings_model.h5')\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    #image = image.crop(coords_for_crop(image_path))\n",
    "    image = image.resize((600, 600))  # Ensure the image is 600x600 pixels\n",
    "    #image.show()\n",
    "    image = np.array(image) / 255.0  # Normalize the image\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "\n",
    "def display_results(image_path):\n",
    "    # Path to the random image\n",
    "    random_image_path = image_path  # Replace with the actual path\n",
    "\n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocess_image(random_image_path)\n",
    "\n",
    "    # Predict the ratings\n",
    "    predicted_ratings = model.predict(preprocessed_image)\n",
    "\n",
    "    # Print the predicted ratings\n",
    "    usaldusvaarus, ilu, intelligents = predicted_ratings[0]\n",
    "    print(f\"Predicted Reliability (usaldusväärsus): {usaldusvaarus}\")\n",
    "    print(f\"Predicted Attractiveness (ilu): {ilu}\")\n",
    "    print(f\"Predicted Intelligence (intelligents): {intelligents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff89c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYLER RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Predicted Reliability (usaldusväärsus): 4.001458644866943\n",
      "Predicted Attractiveness (ilu): 4.326530456542969\n",
      "Predicted Intelligence (intelligents): 4.633413314819336\n",
      "KIM RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Predicted Reliability (usaldusväärsus): 4.8442301750183105\n",
      "Predicted Attractiveness (ilu): 7.144835948944092\n",
      "Predicted Intelligence (intelligents): 7.220454692840576\n",
      "BRAD RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "Predicted Reliability (usaldusväärsus): 7.994103908538818\n",
      "Predicted Attractiveness (ilu): 8.526636123657227\n",
      "Predicted Intelligence (intelligents): 7.176937580108643\n",
      "HOMELESS RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "Predicted Reliability (usaldusväärsus): 3.338634490966797\n",
      "Predicted Attractiveness (ilu): 4.160274505615234\n",
      "Predicted Intelligence (intelligents): 4.202895164489746\n",
      "GIRL RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Predicted Reliability (usaldusväärsus): 6.090631484985352\n",
      "Predicted Attractiveness (ilu): 6.4580159187316895\n",
      "Predicted Intelligence (intelligents): 6.231784820556641\n",
      "HOMELESS RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "Predicted Reliability (usaldusväärsus): 3.338634490966797\n",
      "Predicted Attractiveness (ilu): 4.160274505615234\n",
      "Predicted Intelligence (intelligents): 4.202895164489746\n",
      "OLD_MAN RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "Predicted Reliability (usaldusväärsus): 4.635649681091309\n",
      "Predicted Attractiveness (ilu): 5.2997660636901855\n",
      "Predicted Intelligence (intelligents): 5.339832305908203\n",
      "AIRBRUSHED RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "Predicted Reliability (usaldusväärsus): 5.652440071105957\n",
      "Predicted Attractiveness (ilu): 5.758391857147217\n",
      "Predicted Intelligence (intelligents): 5.533234119415283\n",
      "OBAMA RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "Predicted Reliability (usaldusväärsus): 5.6881632804870605\n",
      "Predicted Attractiveness (ilu): 8.267254829406738\n",
      "Predicted Intelligence (intelligents): 8.126022338867188\n",
      "AI_GIRL RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "Predicted Reliability (usaldusväärsus): 4.578141689300537\n",
      "Predicted Attractiveness (ilu): 5.997496128082275\n",
      "Predicted Intelligence (intelligents): 5.469697952270508\n",
      "GIRL_IN_FIELD RATING:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "Predicted Reliability (usaldusväärsus): 4.901668071746826\n",
      "Predicted Attractiveness (ilu): 6.320193767547607\n",
      "Predicted Intelligence (intelligents): 6.881258487701416\n"
     ]
    }
   ],
   "source": [
    "links = [\"tyler.jpg\",\n",
    "        \"kim.jpg\",\n",
    "        \"brad.jpg\",\n",
    "        \"homeless.png\",\n",
    "        \"girl.png\",\n",
    "        \"homeless.png\",\n",
    "        \"old_man.png\",\n",
    "        \"airbrushed.jpg\",\n",
    "        \"obama.png\",\n",
    "        \"ai_girl.png\",\n",
    "        \"girl_in_field.jpg\"]\n",
    "\n",
    "for link in links:\n",
    "    name = link.split(\".\")[0].upper()\n",
    "    print(f'{name} RATING:')\n",
    "    display_results('./res/people/'+link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
